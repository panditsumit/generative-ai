{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f49479-991a-4246-b6f7-114e15fbf8b0",
   "metadata": {},
   "source": [
    "# Expose an Agent as an MCP Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e2de5-4ec7-46b0-8dee-10402217d962",
   "metadata": {},
   "source": [
    "## You can read about MCP in detail from here [MCP Getting Started](https://modelcontextprotocol.io/docs/getting-started/intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582a316-6c48-44cb-9e24-f8c497719913",
   "metadata": {},
   "source": [
    "### In below section we will built up MCP server for the Food Agent.\n",
    "### <ul><li>First Create Food Agent</li><li>Add Tools to the Agent</li><li>Expose Agent as MCP Server</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d4bfd-a812-4349-9c67-f6d07cff340f",
   "metadata": {},
   "source": [
    "# Create Agents and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283916f-af0c-49c0-8722-f4ecb685f095",
   "metadata": {},
   "source": [
    "### Here we will create the Agents and then all the function tools to it. Functions like get_random_meal(), get_meal_by_name() are the two functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation-header",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Before running this notebook, make sure you have the `agent-framework` package installed. Refer to `basic_food_agent.ipynb` for detailed installation instructions.\n",
    "\n",
    "```bash\n",
    "!pip install -U agent-framework --pre\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f154c36-8df0-43e0-a396-da0e37254de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation refer 'basic_food_agent.ipynb' , installation section\n",
    "# !pip install -U agent-framework --pre\n",
    "# You can see the basic_food_agent.ipynb for basic agent run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-functions-header",
   "metadata": {},
   "source": [
    "## API Helper Functions\n",
    "\n",
    "These functions interact with [TheMealDB API](https://www.themealdb.com/api.php) to fetch meal data:\n",
    "\n",
    "- `_clean_meal_data()`: Helper function that restructures raw API response by combining ingredients and their measures into a clean, LLM-friendly format.\n",
    "- `get_random_meal()`: Retrieves a random meal recipe from the database.\n",
    "- `get_meal_by_name()`: Searches for a specific meal recipe by name.\n",
    "\n",
    "These functions use the `Annotated` type hint with `Field` to provide descriptions that help the LLM understand when and how to use each tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db82a49-a17f-4bd6-8fe8-c8399e5406e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Annotated, List, Dict, Any, Optional\n",
    "from pydantic import Field\n",
    "\n",
    "# Clean the MealDB response for the LLM\n",
    "def _clean_meal_data(meal: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Helper function to restructure the raw meal API response into a clean, \n",
    "    LLM-friendly format by combining ingredients and measures.\n",
    "    \"\"\"\n",
    "    if not meal:\n",
    "        return {}\n",
    "\n",
    "    # Combine ingredients and measures into a single list\n",
    "    ingredients = []\n",
    "    for i in range(1, 21):\n",
    "        ing = meal.get(f\"strIngredient{i}\")\n",
    "        measure = meal.get(f\"strMeasure{i}\")\n",
    "        if ing and ing.strip():\n",
    "            ingredients.append(f\"{measure.strip()} {ing.strip()}\".strip())\n",
    "\n",
    "    return {\n",
    "        \"id\": meal.get(\"idMeal\"),\n",
    "        \"name\": meal.get(\"strMeal\"),\n",
    "        \"category\": meal.get(\"strCategory\"),\n",
    "        \"area\": meal.get(\"strArea\"),\n",
    "        \"instructions\": meal.get(\"strInstructions\"),\n",
    "        \"ingredients\": ingredients,\n",
    "        \"tags\": meal.get(\"strTags\"),\n",
    "        \"youtube_link\": meal.get(\"strYoutube\")\n",
    "    }\n",
    "\n",
    "# Get random meal for today\n",
    "def get_random_meal() -> str:\n",
    "    \"\"\"\n",
    "    Retrieves a random meal recipe from the database. \n",
    "    Useful when the user wants a surprise suggestion or explicitly asks for a random recommendation.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string containing the meal name, ingredients, and cooking instructions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://www.themealdb.com/api/json/v1/1/random.php\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data.get(\"meals\"):\n",
    "            return json.dumps({\"error\": \"No meal found.\"})\n",
    "            \n",
    "        meal = _clean_meal_data(data[\"meals\"][0])\n",
    "        return json.dumps(meal, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Failed to fetch random meal: {str(e)}\"})\n",
    "\n",
    "# Here we get the meal by name\n",
    "def get_meal_by_name(\n",
    "    meal_name: Annotated[str, Field(description=\"The name of the meal to search for (e.g., 'Arrabiata', 'Burger').\")]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Searches for a specific meal recipe by name. \n",
    "    Use this when the user asks for a specific dish or wants to know how to cook a named item.\n",
    "\n",
    "    Args:\n",
    "        meal_name: The name of the dish to search for.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string containing a list of matching meals with their details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The API requires a search query parameter 's'\n",
    "        response = requests.get(f\"https://www.themealdb.com/api/json/v1/1/search.php?s={meal_name}\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data.get(\"meals\"):\n",
    "            return json.dumps({\"status\": \"not_found\", \"message\": f\"No meals found with the name '{meal_name}'.\"})\n",
    "        \n",
    "        # Clean and limit results (e.g., top 3 matches to save tokens)\n",
    "        results = [_clean_meal_data(m) for m in data[\"meals\"][:3]]\n",
    "        return json.dumps(results, indent=2)\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Failed to search for meal: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Import the required libraries and Microsoft Agent Framework components:\n",
    "\n",
    "- `asyncio`: For async/await support\n",
    "- `os`: For accessing environment variables\n",
    "- `json`: For JSON parsing\n",
    "- `dotenv`: For loading environment variables from `.env` file\n",
    "- `ChatAgent`: The main Agent class for building conversational AI agents\n",
    "- `OpenAIChatClient`: Client for LLM inference using OpenAI-compatible endpoints (OpenRouter in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbc0c8e-5ede-4372-9f15-4bc75dcccb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core dependencies to create the agent, for Agent Framework\n",
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# Core components for building Agent, tool-enabled agents\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-load-header",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "Load environment variables from a `.env` file in the project directory. This file should contain:\n",
    "- `OPENROUTER_ENDPOINT`: The OpenRouter API endpoint URL\n",
    "- `OPENROUTER_API_KEY`: Your OpenRouter API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350ebfe7-afc7-4973-9971-186d0164dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment file\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat-client-header",
   "metadata": {},
   "source": [
    "## Setup Chat Client\n",
    "\n",
    "Configure the `OpenAIChatClient` to use OpenRouter API, which provides access to various LLM models including NVIDIA's Nemotron model. The client is configured with:\n",
    "\n",
    "- `base_url`: The OpenRouter API endpoint\n",
    "- `api_key`: Your API key for authentication\n",
    "- `model_id`: The specific model to use (NVIDIA Nemotron 3 Nano 30B in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d94fc3-e35f-404e-a06c-1dc73b5c8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAIChatClient for LLM Inference - Here we will use OpenRouter API which is compatible with OpenAI and NVIDIA 30B model\n",
    "# This client connects to the OpenRouter Models which are OpenAI-compatible endpoint\n",
    "# Environment variables required\n",
    "# OPENROUTER_ENDPOINT - \n",
    "# OPENROUTER_API_KEY\n",
    "openai_chat_client = OpenAIChatClient(\n",
    "    base_url=os.environ.get(\"OPENROUTER_ENDPOINT\"),\n",
    "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
    "    model_id=\"nvidia/nemotron-3-nano-30b-a3b:free\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-instructions-header",
   "metadata": {},
   "source": [
    "## Define Food Agent Instructions\n",
    "\n",
    "The `AGENT_INSTRUCTIONS` define the behavior of our Food Agent:\n",
    "\n",
    "1. **Tool Usage**: Always use the provided tools (API functions) to answer questions\n",
    "2. **Response Format**: Start with appetizing descriptions, list ingredients clearly, summarize instructions, include YouTube links if available\n",
    "3. **Constraints**: Keep responses under 200 words, summarize long instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7978aa-89ee-44a8-98b9-e705476ded1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = \"FoodAgent\"\n",
    "\n",
    "AGENT_INSTRUCTIONS = \"\"\"You are an expert AI Chef dedicated to helping users discover and prepare delicious meals.\n",
    "\n",
    "CORE BEHAVIORS:\n",
    "1. **Tool Usage**: You have access to a recipe database. ALWAYS use the provided tools to answer questions about recipes. Do not guess or hallucinate ingredients.\n",
    "   - Use `get_meal_by_name` when the user asks for a specific dish.\n",
    "   - Use `get_random_meal` when the user is undecided, asks for a suggestion, or wants a surprise.\n",
    "\n",
    "2. **Response Format**: \n",
    "   - Start with an appetizing description of the dish.\n",
    "   - List key ingredients clearly (based on the tool output).\n",
    "   - Summarize the cooking instructions to be easy to follow.\n",
    "   - If the tool provides a YouTube link, always include it at the end.\n",
    "   - Include Tool Name used for fetching response\n",
    "\n",
    "3. **Constraints**: \n",
    "   - Keep your response friendly but strictly under 200 words. \n",
    "   - If instructions are long, summarize the key steps to fit the word limit.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middleware-header",
   "metadata": {},
   "source": [
    "## Function Middleware\n",
    "\n",
    "Middleware allows you to intercept and modify function calls in the agent framework. The `logging_function_middleware` logs:\n",
    "\n",
    "- The function name before execution\n",
    "- The function result after execution\n",
    "\n",
    "This is useful for debugging and understanding which tools the agent is calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065b555a-e429-4dd7-bbb9-29ff39bfc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add the logging Function middleware since we are working with functions\n",
    "from agent_framework import AgentRunContext, FunctionInvocationContext\n",
    "from typing import Callable , Awaitable\n",
    "\n",
    "# Function middleware \n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Middleware that logs function calls.\"\"\"\n",
    "    print(f\"Calling function: {context.function.name}\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    print(f\"Function result: {context.result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "food-agent-header",
   "metadata": {},
   "source": [
    "## Create the Food Agent\n",
    "\n",
    "Create the first agent (`food_agent`) with:\n",
    "\n",
    "- `name`: \"FoodAgent\"\n",
    "- `chat_client`: The OpenAI chat client configured earlier\n",
    "- `instructions`: The behavior instructions defined above\n",
    "- `tools`: The API helper functions (`get_random_meal`, `get_meal_by_name`)\n",
    "- `middleware`: The logging middleware for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36da0135-40a6-4041-a619-86420ebf5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the foodAgent\n",
    "# create the agent remember we are not using any tools here, this is simple example\n",
    "food_agent = ChatAgent(\n",
    "    name = AGENT_NAME,\n",
    "    chat_client=openai_chat_client,\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    tools=[get_random_meal, get_meal_by_name],\n",
    "    middleware=[logging_function_middleware]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f027b9-a585-4803-8ad0-47e54d310cdb",
   "metadata": {},
   "source": [
    "### Let's turn the Food Agent into an MCP Server\n",
    "> **Note:** I am converting here ChatAgent of Microsoft Framework to MCP Server, for simplicity, but it's better to use simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3234b4-42fd-45d5-a742-16e45f7d29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = food_agent.as_mcp_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271248a4-f402-4d34-a8a4-327699d55b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anyio\n",
    "from mcp.server.stdio import stdio_server\n",
    "\n",
    "async def run():\n",
    "    async def handle_stdin():\n",
    "        async with stdio_server() as (read_stream, write_stream):\n",
    "            await server.run(read_stream, write_stream, server.create_initialization_options())\n",
    "\n",
    "    await handle_stdin()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     anyio.run(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992efcb-8484-469b-9cc9-d82bfa1e7816",
   "metadata": {},
   "source": [
    "#### the whole mcp server is in python file `agent_as_mcp_tool.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba38d2-b47e-401d-8faa-08cace405a62",
   "metadata": {},
   "source": [
    "### Accessing MCP Server as Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ca4ff0-34cb-4cda-a7be-d77d8de7530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connecting to /home/rancore/github/generative-ai/microsoft-agent-framework/agent_as_mcp_tool.py...\n",
      "‚úÖ Session Initialized\n",
      "\n",
      "üìã Found 1 tools:\n",
      " - FoodAgent\n",
      "\n",
      "ü§ñ Asking 'FoodAgent' to find a random meal...\n",
      "\n",
      "‚¨áÔ∏è Response from Agent:\n",
      "üçΩÔ∏è **Fish Pie** ‚Äì A classic British comfort dish with flaky white fish, creamy sauce, and buttery mashed potatoes crowned with golden cheese.  \n",
      "\n",
      "**Ingredients**  \n",
      "- 900‚ÄØg floury potatoes  \n",
      "- 600‚ÄØml semi‚Äëskimmed milk  \n",
      "- 800‚ÄØg white fish fillets  \n",
      "- 2‚ÄØtbsp olive oil  \n",
      "- 1‚ÄØtbsp plain flour  \n",
      "- Nutmeg, double cream, leeks, artichokes, prawns, parsley, dill, lemon zest & juice, Gruy√®re cheese  \n",
      "\n",
      "**Quick steps**  \n",
      "1Ô∏è‚É£ Boil potatoes, mash with olive oil and season.  \n",
      "2Ô∏è‚É£ Poach fish in milk, flake and place in a baking dish.  \n",
      "3Ô∏è‚É£ Make a roux with flour, add reserved milk, thicken, stir in cream and nutmeg.  \n",
      "4Ô∏è‚É£ Mix sauce with artichokes, leek, prawns, herbs, lemon, then pour over fish.  \n",
      "5Ô∏è‚É£ Top with mash, sprinkle cheese, and bake at 190‚ÄØ¬∞C for 35‚Äë40‚ÄØmin until bubbling and golden.  \n",
      "\n",
      "Enjoy the crisp, cheesy crust paired with wilted greens!  \n",
      "\n",
      "üìπ Watch the full recipe here: https://www.youtube.com/watch?v=2sX4fCgg-UI  \n",
      "\n",
      "Tool used: get_random_meal\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load Env Vars\n",
    "load_dotenv() \n",
    "\n",
    "# 2. Get Absolute Path to the Server Script\n",
    "script_path = os.path.abspath(\"agent_as_mcp_tool.py\")\n",
    "\n",
    "# Verify file exists\n",
    "if not os.path.exists(script_path):\n",
    "    raise FileNotFoundError(f\"Could not find server script at: {script_path}\")\n",
    "\n",
    "# 3. Configure Server Parameters\n",
    "server_params = StdioServerParameters(\n",
    "    command=sys.executable,\n",
    "    args=[script_path],\n",
    "    env=os.environ.copy()\n",
    ")\n",
    "\n",
    "async def run_test():\n",
    "    print(f\"üîå Connecting to {script_path}...\")\n",
    "    \n",
    "    try:\n",
    "        async with stdio_client(server_params) as (read, write):\n",
    "            async with ClientSession(read, write) as session:\n",
    "                await session.initialize()\n",
    "                print(\"‚úÖ Session Initialized\")\n",
    "\n",
    "                # List Tools\n",
    "                tools = await session.list_tools()\n",
    "                print(f\"\\nüìã Found {len(tools.tools)} tools:\")\n",
    "                for tool in tools.tools:\n",
    "                    print(f\" - {tool.name}\")\n",
    "\n",
    "                # ---------------------------------------------------------\n",
    "                # FIX IS HERE: Change 'message' to 'task'\n",
    "                # ---------------------------------------------------------\n",
    "                print(f\"\\nü§ñ Asking 'FoodAgent' to find a random meal...\")\n",
    "                \n",
    "                result = await session.call_tool(\n",
    "                    \"FoodAgent\", \n",
    "                    arguments={\"task\": \"I am hungry, give me a random meal recommendation\"}\n",
    "                )\n",
    "                \n",
    "                if result.content:\n",
    "                    print(\"\\n‚¨áÔ∏è Response from Agent:\")\n",
    "                    print(result.content[0].text)\n",
    "                # ---------------------------------------------------------\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Run in Jupyter\n",
    "await run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcdd48-deb2-4879-8155-8dd175af50fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73352fa0-b867-4790-b72e-823613feecfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
